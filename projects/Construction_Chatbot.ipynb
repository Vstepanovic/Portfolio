{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4afe8af0",
   "metadata": {},
   "source": [
    "# Construction d'un simple Chatbot sur Python (avec NLTK)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88776a91",
   "metadata": {},
   "source": [
    "### Télécharchement et installation de NTLK\n",
    "\n",
    "NTLK est une plateforme qui nous permet de construire des  programme Python qui va travailler avec les données du languages humains. Cela va nous donner des interfaces faciles d'utilisation, et permet la réalisation d'introductions pratiques pour le traitement des langues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9572aea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\boomi\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\boomi\\anaconda3\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: click in c:\\users\\boomi\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\boomi\\anaconda3\\lib\\site-packages (from nltk) (2023.3.23)\n",
      "Requirement already satisfied: joblib in c:\\users\\boomi\\anaconda3\\lib\\site-packages (from nltk) (1.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\boomi\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install nltk\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('popular', quiet=True) #pour télécharger les packages populaires\n",
    "#nltk.download('punkt') \n",
    "#nltk.download('wordnet') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d2b742",
   "metadata": {},
   "source": [
    "### Importation des librairies nécessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "284970f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import random\n",
    "import string # pour traîter les chaînes standards\n",
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060aa671",
   "metadata": {},
   "source": [
    "## Lecture du corpus\n",
    "\n",
    "Dans ce projet nous allons utiliser la page Wikipedia comme notre corpus. Nous allons copier le contenu de la page et le placer dans un fichier texte nommé 'chatbox.txt'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9f976c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(r'C:\\Users\\Boomi\\Desktop\\projects\\Chatbot.txt', 'r', errors ='ignore')\n",
    "raw = f.read()\n",
    "raw = raw.lower() # convertit en tout en minuscule pour pas que l'algorithme traite les mots différement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eef5650",
   "metadata": {},
   "source": [
    "Ici le problème est que notre texte est en format strings. Or notre algorithme a besoin de paramètres numériques pour pouvoir effectuer la tâche. Nous avons alors besoin de procéder à des conversions avant de démarrer notre projet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00d619b",
   "metadata": {},
   "source": [
    "### Tokenisation\n",
    "Processus de conversion du format strings du texte en liste de token (mots qu'on veut)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ec99d103",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_tokens = nltk.sent_tokenize(raw) #consersion en liste de phrases\n",
    "word_tokens = nltk.word_tokenize(raw) #conversion en liste de mots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4aa187",
   "metadata": {},
   "source": [
    "Nous allons maintenant définir une fontion 'LemTokens' qui prendra en entrée les tokens et retournera les tokens normalisés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "23da5040",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmer = nltk.stem.WordNetLemmatizer() #WordNet est dictionnaire d'anglais orienté inclus dans NLTK.\n",
    "\n",
    "#La lemmatisation est une autre technique utilisée pour réduire les mots fléchis à leur mot racine.\n",
    "\n",
    "def LemTokens(tokens):\n",
    "    return [lemmer.lemmatize(token) for token in tokens]\n",
    "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
    "\n",
    "def LemNormalize(text):\n",
    "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60ecb18",
   "metadata": {},
   "source": [
    "Nous allons ensuite définir une foncion de salutation par le bot : si l'entrée d'un utilisateur est une salutation, le bot en renverra une aussi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8a9867bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "SALUTATION_INPUTS = (\"bonjour\", \"salut\", \"hello\", \"Hey\", \"bonsoir\")\n",
    "SALUTATION_REPONSES = (\"bonjour\", \"salut\", \"hello\", \"Hey\", \"bonsoir\", \"...\", \"Je suis content que tu me parles !\")\n",
    "\n",
    "def salutation(sentence):\n",
    "    for word in sentence.split():\n",
    "        if word.lower() in SALUTATION_INPUTS:\n",
    "            return random.choice(SALUTATION_REPONSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed3bb55",
   "metadata": {},
   "source": [
    "## Génération de réponse\n",
    "\n",
    "Pour générer une réponse de notre bot pour les questions, nous allons utilisé le concept de smilarité de document.\n",
    "Nous allons définir une réponse de fonction qui recherche dans l'énoncé de l'utilisateur un ou plusieurs mots-clés connus et renvoie l'une des nombreuses réponses possibles. Mais si notre bot ne trouve pas de correspondance à un mot-clé, alors il renverra une réponse telle que \"je suis désolé ! je n'ai pas compris\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e0fb1fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reponse(utilisateur_reponse):\n",
    "    robot_reponse=''\n",
    "    sent_tokens.appebd(utilisateur_reponse)\n",
    "    TfidVec =TfidfVectorizer(tokenizer=LemNormalize, stop_words='français')\n",
    "    tfidf = TfidfVec.fit_transform(sent_tokens)\n",
    "    vals = cosine_similarity(tfidf[-1], tfidf)\n",
    "    idx=vals.argsort()[0][-2]\n",
    "    flat = vals.flatten()\n",
    "    flat.sort()\n",
    "    req_tfidf = flat[-2]\n",
    "    if(req_tfidf==0):\n",
    "        robot_reponse=robot_reponse+\" Je suis désolé ! je n'ai pas compris\"\n",
    "        return robot_reponse\n",
    "    else:\n",
    "        robot_reponse = robot_reponse+sent_tokens[idx]\n",
    "        return robot_reponse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad713720",
   "metadata": {},
   "source": [
    "Nous allons compléter les lignes que nous voulons que notre bot dise au début et à la fin d'une conversation en fonction de ce que l'utilisateur va entrer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "54e286ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROBOT: Mon nom est MrRobot. Je peux répondre à vos questions sur les Chatbots. Si vous voulez quitter écrivez bye\n",
      "salut\n",
      "ROBOT: salut\n",
      "bonjour\n",
      "ROBOT: hello\n",
      "bonsoir\n",
      "ROBOT: bonjour\n",
      "bye\n",
      "ROBOT: Bye! Prends soin de toi\n"
     ]
    }
   ],
   "source": [
    "flag =True \n",
    "print(\"ROBOT: Mon nom est MrRobot. Je peux répondre à vos questions sur les Chatbots. Si vous voulez quitter écrivez bye\")\n",
    "while(flag==True):\n",
    "    utilisateur_reponse = input()\n",
    "    utilisateur_reponse=utilisateur_reponse.lower()\n",
    "    if(utilisateur_reponse!='bye'):\n",
    "        if(utilisateur_reponse=='merci' or utilisateur_reponse=='je te remercie' ):\n",
    "            flag=False\n",
    "            print(\"ROBOT: De rien...\")\n",
    "        else:\n",
    "            if(salutation(utilisateur_reponse)!=None):\n",
    "                print(\"ROBOT: \"+salutation(utilisateur_reponse))\n",
    "            else:\n",
    "                print(\"ROBOT: \",end=\"\")\n",
    "                print(response(utilisateur_reponse))\n",
    "                sent_tokens.remove(utilisateur_reponse)\n",
    "    else:\n",
    "        flag=False\n",
    "        print(\"ROBOT: Bye! Prends soin de toi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc73cda7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
